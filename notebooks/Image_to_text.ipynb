{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6652a472",
   "metadata": {},
   "source": [
    "# Insta Caption Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21aa74",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f16527-fcab-41e0-bce8-634fae58b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import Image, display, HTML\n",
    "from PIL import Image\n",
    "import base64 \n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7d79ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thor_01/miniconda3/envs/textgen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b223e8",
   "metadata": {},
   "source": [
    "#### Downloading the model for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4f4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "# # Specify your local directory where you want to save the model and tokenizer\n",
    "# save_directory = \"./blip_image_captioning_large\"\n",
    "\n",
    "# processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "# model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "# # Save the model and tokenizer to the directory\n",
    "# processor.save_pretrained(save_directory)\n",
    "# model.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153aa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d1e1e72",
   "metadata": {},
   "source": [
    "#### Loading the model for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45bb6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "# Specify your local directory where you've saved the model and tokenizer\n",
    "load_directory = \"./blip_image_captioning_large\"\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(load_directory)\n",
    "model = BlipForConditionalGeneration.from_pretrained(load_directory).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61879e",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22def7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image from the web\n",
    "\n",
    "img_url = 'https://cdn.omahaschoolofmusicanddance.com/wp-content/uploads/2020/01/21095647/playing-piano-blog.jpg' \n",
    "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef139957",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image = Image.open('/home/thor_01/Downloads/IMG_6063.jpg').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33956b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photography of an empty street with buildings and trees in the background,\n"
     ]
    }
   ],
   "source": [
    "# conditional image captioning\n",
    "text = \"a photography of\"\n",
    "inputs = processor(raw_image, text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "out = model.generate(**inputs, min_length=15, max_length=100, do_sample=False, repetition_penalty=1.5)\n",
    "output_text = processor.decode(out[0], skip_special_tokens=True)\n",
    "print(output_text)\n",
    "\n",
    "\n",
    "# # unconditional image captioning\n",
    "# inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# out = model.generate(**inputs, min_length=5, max_length=100, do_sample=False, repetition_penalty=1.5)\n",
    "# output_text = processor.decode(out[0], skip_special_tokens=True)\n",
    "# print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9656fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is a street with buildings and trees on both sides\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "111cdfec",
   "metadata": {},
   "source": [
    "# Loading LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c682ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2ab1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"/home/thor_01/Documents/05_AI_app_Gradio/llama-2-13b-chat.Q5_K_M.gguf\", model_file=\"llama-2-13b-chat.q4_K_M.gguf\", model_type=\"llama\", gpu_layers=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628ee11",
   "metadata": {},
   "source": [
    "### Creating the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "893f6c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option one\n",
      "'life is full of paths, we choose which ones to follow, some lead to happiness while others to loneliness.' #philosophy #emptystreet #lifelessons \n",
      "option two\n",
      "'the world may seem empty, but our imagination can fill it with endless possibilities' #creativity #imagination #emptyworld\n",
      "option three\n",
      "'sometimes the most beautiful things are found in the quietest places' #minimalism # simplicity #emptystreet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = f\"\"\"\n",
    "Create 3 alternatives for a philosofical caption of maximum 80 tokens for an instagram post based on the following photo description, add 5 relevant hastags to each option:\n",
    "'{output_text}'\n",
    "\"\"\"\n",
    "response = llm(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842133e",
   "metadata": {},
   "source": [
    "### Adding interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9b98a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(raw_image, style):\n",
    "    # 1. conditional image captioning\n",
    "    text = \"a photography of\"\n",
    "    inputs = processor(raw_image, text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    out = model.generate(**inputs, min_length=15, max_length=100, do_sample=False, repetition_penalty=1.5)\n",
    "    output_text = processor.decode(out[0], skip_special_tokens=True)\n",
    "    # 2. CREATING PROMPT\n",
    "    style = 'philosofical'\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Create 3 alternatives for a {style} caption of maximum 80 tokens for an instagram post based on the following photo description, add 5 relevant hastags to each option:\n",
    "    '{output_text}'\n",
    "    \"\"\"\n",
    "    response = llm(prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c25c9a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "    \n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=get_answer, \n",
    "                    inputs=[gr.Image(label=\"Image to get capture\")],\n",
    "                    outputs=[gr.Textbox(label=\"Result\", lines=5)],\n",
    "                    title=\"Image to Poetic Caption\",\n",
    "                    description=\"Get poetic caption for any image\"\n",
    "                   )\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0456417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Define the function for generating an answer based on the given raw image and style.\n",
    "def get_answer(raw_image, style):\n",
    "    # 1. conditional image captioning\n",
    "    text = \"a photography of\"\n",
    "    inputs = processor(raw_image, text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    out = model.generate(**inputs, min_length=15, max_length=100, do_sample=False, repetition_penalty=1.5)\n",
    "    output_text = processor.decode(out[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 2. CREATING PROMPT\n",
    "    # Note: No need to hardcode style as 'philosofical' as it's an input now.\n",
    "    prompt = f\"\"\"\n",
    "    Create 3 alternatives for a {style} caption of maximum 80 tokens for an Instagram post based on the following photo description, add 5 relevant hashtags to each option:\n",
    "    '{output_text}'\n",
    "    \"\"\"\n",
    "    response = llm(prompt)\n",
    "    return response\n",
    "\n",
    "# Close any existing Gradio interfaces.\n",
    "gr.close_all()\n",
    "\n",
    "# Define the Gradio interface.\n",
    "demo = gr.Interface(\n",
    "    fn=get_answer, \n",
    "    inputs=[\n",
    "        gr.Image(label=\"Image to get capture\"),\n",
    "        gr.Dropdown(choices=[\"philosophical\", \"humorous\", \"sarcastic\", \"romantic\", \"adventurous\", \"mystical\", \"nostalgic\", \"inspirational\", \"whimsical\"], label=\"Caption Style\")\n",
    "    ],\n",
    "    outputs=[gr.Textbox(label=\"Result\", lines=5)],\n",
    "    title=\"Image to Poetic Caption\",\n",
    "    description=\"Get poetic caption for any image\"\n",
    ")\n",
    "\n",
    "# Launch the interface.\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
